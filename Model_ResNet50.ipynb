{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKQtIJmegS6_"
   },
   "source": [
    "1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "tXzvHwn0gVJu",
    "outputId": "e7e5e02c-b052-450b-b45f-28bdd0d95a7c"
   },
   "outputs": [],
   "source": [
    "#1.1 class distribution for whole dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # For progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataset_path=\"Plant Village Dataset/data/data with aug/\"\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "class_labels = []\n",
    "\n",
    "# Iterate over classes and count the images\n",
    "for idx, class_dir in enumerate(os.listdir(dataset_path)):\n",
    "    class_path = os.path.join(dataset_path, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        class_labels.append(f'class{idx + 1}')\n",
    "        class_counts[f'class{idx + 1}'] = len(os.listdir(class_path))\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Gh4zl1YTgXYO",
    "outputId": "99a0c514-4642-4d56-efa9-aaf8637faf3d"
   },
   "outputs": [],
   "source": [
    "# 1.2 Display random samples from each class\n",
    "for class_dir in random.sample(os.listdir(dataset_path), 4):  # Random 4 classes\n",
    "    class_path = os.path.join(dataset_path, class_dir)\n",
    "    image_file = random.choice(os.listdir(class_path))\n",
    "    image = Image.open(os.path.join(class_path, image_file))\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(class_dir)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "9XE6aZGjgaA-",
    "outputId": "dc4ccdf3-0dd2-4199-a935-57c09f7fb07d"
   },
   "outputs": [],
   "source": [
    "# 1.3 sample augmented images\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "data_dir = \"Plant Village Dataset/data/data with aug/\"\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(51)\n",
    "\n",
    "# Get a mapping of class directories to image paths\n",
    "class_images = {}\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for dir_name in dirs:  # Loop through each class folder\n",
    "        class_dir = os.path.join(root, dir_name)\n",
    "        images = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if images:  # Ensure the class has images\n",
    "            class_images[dir_name] = images\n",
    "\n",
    "# Select one random image from each class\n",
    "selected_images = []\n",
    "for class_name, images in class_images.items():\n",
    "    selected_images.append(random.choice(images))  # Randomly pick one image from the class\n",
    "\n",
    "# Display up to 5 sample images from different classes\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(selected_images):\n",
    "        img = Image.open(selected_images[i])  # Open image without resizing\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "plt.suptitle(\"Sample Images From Different Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QpS6HQY3gdb2",
    "outputId": "eb711453-2b70-45be-e51a-e36b38c47347"
   },
   "outputs": [],
   "source": [
    "# 1.4 all of Try1 eda.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "np.bool = bool  # Temporary fix for deprecated alias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "\n",
    "# Set paths\n",
    "IMAGE_PATH = \"Plant Village Dataset/data/data with aug/\"  # Path to training images (adjust as needed)\n",
    "\n",
    "# Function to load an image\n",
    "def load_image(image_id):\n",
    "    \"\"\"Loads an image given its file name without extension.\"\"\"\n",
    "    file_path = image_id + \".jpg\"\n",
    "    image = cv2.imread(os.path.join(IMAGE_PATH, file_path))\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize one leaf image\n",
    "def visualize_one_leaf(image):\n",
    "    \"\"\"Displays a single leaf image using Plotly.\"\"\"\n",
    "    resized_image = cv2.resize(image, (205, 136))\n",
    "    fig = px.imshow(resized_image)\n",
    "    fig.update_layout(coloraxis_showscale=False, title=\"Leaf Image\")\n",
    "    fig.show()\n",
    "\n",
    "# Visualize channel distributions\n",
    "def visualize_channel_distributions(image):\n",
    "    \"\"\"Plots the distributions of RGB channels for a single image.\"\"\"\n",
    "    channels = {\"Red\": image[:, :, 0].flatten(),\n",
    "                \"Green\": image[:, :, 1].flatten(),\n",
    "                \"Blue\": image[:, :, 2].flatten()}\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for channel, values in channels.items():\n",
    "        sns.histplot(values, bins=50, kde=True, label=channel, color=channel.lower())\n",
    "    plt.title(\"Channel Intensity Distributions\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample leaves from different categories\n",
    "def visualize_sample_leaves(image_path, categories, num_samples=5):\n",
    "    \"\"\"Displays sample leaves for each category.\"\"\"\n",
    "    plt.figure(figsize=(15, len(categories) * 3))\n",
    "    for i, category in enumerate(categories):\n",
    "        category_path = os.path.join(image_path, category)\n",
    "        images = os.listdir(category_path)[:num_samples]\n",
    "\n",
    "        for j, img_name in enumerate(images):\n",
    "            img = cv2.imread(os.path.join(category_path, img_name))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(len(categories), num_samples, i * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            if j == 0:\n",
    "                plt.ylabel(category, fontsize=12)\n",
    "    plt.suptitle(\"Sample Leaves from Each Category\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize target distributions\n",
    "def visualize_targets(image_path):\n",
    "    \"\"\"Plots the distribution of categories (targets) in the dataset.\"\"\"\n",
    "    categories = [category for category in os.listdir(image_path) if os.path.isdir(os.path.join(image_path, category))]\n",
    "    category_counts = {category: len(os.listdir(os.path.join(image_path, category))) for category in categories}\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(category_counts.keys()), y=list(category_counts.values()))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Target Distribution\")\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load a single image for visualization\n",
    "    categories = [category for category in os.listdir(IMAGE_PATH) if os.path.isdir(os.path.join(IMAGE_PATH, category))]\n",
    "    sample_category = categories[0]\n",
    "    sample_image_path = os.path.join(IMAGE_PATH, sample_category, os.listdir(os.path.join(IMAGE_PATH, sample_category))[0])\n",
    "    sample_image = cv2.imread(sample_image_path)\n",
    "    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 1. Visualize one leaf\n",
    "    visualize_one_leaf(sample_image)\n",
    "\n",
    "    # 2. Visualize channel distributions\n",
    "    visualize_channel_distributions(sample_image)\n",
    "\n",
    "    # 3. Visualize sample leaves belonging to different categories\n",
    "    visualize_sample_leaves(IMAGE_PATH, categories, num_samples=5)\n",
    "\n",
    "    # 4. Visualize target distributions\n",
    "    visualize_targets(IMAGE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz-itAyOgiZ-"
   },
   "source": [
    "2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyqyzQo0jGDn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define directories\n",
    "original_dir = \"Plant Village Dataset/data/data with aug/\"  # Original dataset directory\n",
    "split_dir = \"split_dataset/\"  # Directory for split data\n",
    "preprocessed_dir = \"preprocessed_dataset/\"  # Directory for preprocessed data\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (224, 224)  # Resizing dimensions\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.1\n",
    "\n",
    "# Step 1: Split data into train, val, and test\n",
    "def split_data(original_dir, split_dir, test_size, val_size):\n",
    "    if not os.path.exists(split_dir):\n",
    "        os.makedirs(split_dir)\n",
    "\n",
    "    for class_name in os.listdir(original_dir):\n",
    "        class_dir = os.path.join(original_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(class_dir)\n",
    "        images_train, images_test = train_test_split(images, test_size=test_size, random_state=42)\n",
    "        images_train, images_val = train_test_split(images_train, test_size=val_size / (1 - test_size), random_state=42)\n",
    "\n",
    "        # Save split data\n",
    "        for split_name, split_images in zip([\"train\", \"val\", \"test\"], [images_train, images_val, images_test]):\n",
    "            split_class_dir = os.path.join(split_dir, split_name, class_name)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "            for img in split_images:\n",
    "                shutil.copy(os.path.join(class_dir, img), os.path.join(split_class_dir, img))\n",
    "\n",
    "split_data(original_dir, split_dir, TEST_SIZE, VAL_SIZE)\n",
    "\n",
    "# Step 2: Perform undersampling on the training set\n",
    "def undersample_data(train_dir):\n",
    "    # Define thresholds\n",
    "    high_threshold = 3500  # For classes with more than 5000 images\n",
    "    target_high = 1400     # Reduce these classes to 2000 images\n",
    "\n",
    "    # Process each class\n",
    "    for class_name in os.listdir(train_dir):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        # Get all images in the class\n",
    "        images = os.listdir(class_dir)\n",
    "        num_images = len(images)\n",
    "\n",
    "        # Apply tier-based undersampling\n",
    "        if num_images > high_threshold:\n",
    "            # Undersample to the target for high-volume classes\n",
    "            images_to_remove = random.sample(images, num_images - target_high)\n",
    "            for img in images_to_remove:\n",
    "                os.remove(os.path.join(class_dir, img))\n",
    "\n",
    "        # For other classes, keep the images as they are (1500–2000 or 1000–1500)\n",
    "\n",
    "train_dir = os.path.join(split_dir, \"train\")\n",
    "undersample_data(train_dir)\n",
    "\n",
    "# Step 3: Resize and normalize images, and save them in the preprocessed directory\n",
    "def preprocess_and_save_data(split_dir, preprocessed_dir, img_size):\n",
    "    if not os.path.exists(preprocessed_dir):\n",
    "        os.makedirs(preprocessed_dir)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(split_dir, split)\n",
    "        preprocessed_split_path = os.path.join(preprocessed_dir, split)\n",
    "        os.makedirs(preprocessed_split_path, exist_ok=True)\n",
    "\n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_dir = os.path.join(split_path, class_name)\n",
    "            preprocessed_class_dir = os.path.join(preprocessed_split_path, class_name)\n",
    "            os.makedirs(preprocessed_class_dir, exist_ok=True)\n",
    "\n",
    "            for img_name in os.listdir(class_dir):  # Only iterate over existing images\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                img_array = img_array / 255.0  # Normalize\n",
    "                preprocessed_img_path = os.path.join(preprocessed_class_dir, img_name)\n",
    "                tf.keras.preprocessing.image.save_img(preprocessed_img_path, img_array)\n",
    "\n",
    "# Preprocess and save the final dataset\n",
    "preprocess_and_save_data(split_dir, preprocessed_dir, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 class distribution for training dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # For progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataset_path=\"preprocessed_dataset/train/\"\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "class_labels = []\n",
    "\n",
    "# Iterate over classes and count the images\n",
    "for idx, class_dir in enumerate(os.listdir(dataset_path)):\n",
    "    class_path = os.path.join(dataset_path, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        class_labels.append(f'class{idx + 1}')\n",
    "        class_counts[f'class{idx + 1}'] = len(os.listdir(class_path))\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Display sample augmented images\n",
    "data_dir = \"preprocessed_dataset/train/\"\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data Generator for EDA\n",
    "data_gen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
    "\n",
    "# Load training data for EDA\n",
    "train_gen = data_gen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Display sample augmented images\n",
    "sample_images, _ = next(train_gen)  # Fetch one batch of images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for img, ax in zip(sample_images[:5], axes):  # Show only 5 images\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample Augmented Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 all of Try1 eda.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "np.bool = bool  # Temporary fix for deprecated alias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "\n",
    "# Set paths\n",
    "IMAGE_PATH = \"split_dataset/train/\"  # Path to training images (adjust as needed)\n",
    "\n",
    "# Function to load an image\n",
    "def load_image(image_id):\n",
    "    \"\"\"Loads an image given its file name without extension.\"\"\"\n",
    "    file_path = image_id + \".jpg\"\n",
    "    image = cv2.imread(os.path.join(IMAGE_PATH, file_path))\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize one leaf image\n",
    "def visualize_one_leaf(image):\n",
    "    \"\"\"Displays a single leaf image using Plotly.\"\"\"\n",
    "    resized_image = cv2.resize(image, (205, 136))\n",
    "    fig = px.imshow(resized_image)\n",
    "    fig.update_layout(coloraxis_showscale=False, title=\"Leaf Image\")\n",
    "    fig.show()\n",
    "\n",
    "# Visualize channel distributions\n",
    "def visualize_channel_distributions(image):\n",
    "    \"\"\"Plots the distributions of RGB channels for a single image.\"\"\"\n",
    "    channels = {\"Red\": image[:, :, 0].flatten(),\n",
    "                \"Green\": image[:, :, 1].flatten(),\n",
    "                \"Blue\": image[:, :, 2].flatten()}\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for channel, values in channels.items():\n",
    "        sns.histplot(values, bins=50, kde=True, label=channel, color=channel.lower())\n",
    "    plt.title(\"Channel Intensity Distributions\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample leaves from different categories\n",
    "def visualize_sample_leaves(image_path, categories, num_samples=5):\n",
    "    \"\"\"Displays sample leaves for each category.\"\"\"\n",
    "    plt.figure(figsize=(15, len(categories) * 3))\n",
    "    for i, category in enumerate(categories):\n",
    "        category_path = os.path.join(image_path, category)\n",
    "        images = os.listdir(category_path)[:num_samples]\n",
    "\n",
    "        for j, img_name in enumerate(images):\n",
    "            img = cv2.imread(os.path.join(category_path, img_name))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(len(categories), num_samples, i * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            if j == 0:\n",
    "                plt.ylabel(category, fontsize=12)\n",
    "    plt.suptitle(\"Sample Leaves from Each Category\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize target distributions\n",
    "def visualize_targets(image_path):\n",
    "    \"\"\"Plots the distribution of categories (targets) in the dataset.\"\"\"\n",
    "    categories = [category for category in os.listdir(image_path) if os.path.isdir(os.path.join(image_path, category))]\n",
    "    category_counts = {category: len(os.listdir(os.path.join(image_path, category))) for category in categories}\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(category_counts.keys()), y=list(category_counts.values()))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Target Distribution\")\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load a single image for visualization\n",
    "    categories = [category for category in os.listdir(IMAGE_PATH) if os.path.isdir(os.path.join(IMAGE_PATH, category))]\n",
    "    sample_category = categories[0]\n",
    "    sample_image_path = os.path.join(IMAGE_PATH, sample_category, os.listdir(os.path.join(IMAGE_PATH, sample_category))[0])\n",
    "    sample_image = cv2.imread(sample_image_path)\n",
    "    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 1. Visualize one leaf\n",
    "    visualize_one_leaf(sample_image)\n",
    "\n",
    "    # 2. Visualize channel distributions\n",
    "    visualize_channel_distributions(sample_image)\n",
    "\n",
    "    # 3. Visualize sample leaves belonging to different categories\n",
    "    visualize_sample_leaves(IMAGE_PATH, categories, num_samples=5)\n",
    "\n",
    "    # 4. Visualize target distributions\n",
    "    visualize_targets(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43DrdyfkglYe"
   },
   "source": [
    "3. Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_vF6mwB5glKe",
    "outputId": "9a411180-f580-4b62-ed4e-ee21881b0647"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "preprocessed_dir = \"preprocessed_dataset/\"  # Directory for preprocessed data\n",
    "\n",
    "# Directories (adjust these paths as necessary)\n",
    "train_dir = os.path.join(preprocessed_dir, \"train\")\n",
    "val_dir = os.path.join(preprocessed_dir, \"val\")\n",
    "test_dir = os.path.join(preprocessed_dir, \"test\")\n",
    "\n",
    "# Parameters\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "num_classes = len(os.listdir(train_dir))  # Automatically detect number of classes\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Generate training, validation, and test data\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"saved_models/model_resnet50.h5\")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "y_true = test_gen.classes  # Ground truth labels\n",
    "y_pred = np.argmax(model.predict(test_gen), axis=1)  # Predicted labels\n",
    "class_labels = list(test_gen.class_indices.keys())  # Class names\n",
    "\n",
    "# PrettyTable for classification report\n",
    "classification_rep = classification_report(y_true, y_pred, target_names=class_labels, output_dict=True)\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "for class_name, metrics in classification_rep.items():\n",
    "    if class_name not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "        table.add_row([class_name, metrics['precision'], metrics['recall'], metrics['f1-score'], metrics['support']])\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(table)\n",
    "\n",
    "# Seaborn for confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iClp5tleg0am"
   },
   "source": [
    "4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jW9v8zJug04W"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Paths\n",
    "MODEL_SAVE_PATH = \"saved_models/model_resnet50.h5\"  # Path to the saved model\n",
    "TEST_DIR = \"preprocessed_dataset/test/\"  # Path to the test dataset\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (224, 224)  # Image size (must match training input size)\n",
    "BATCH_SIZE = 32  # Batch size for test data\n",
    "CLASS_LABELS = ['Apple__Apple_scab', 'Apple__Black_rot', 'Apple__Cedar_apple_rust', 'Apple__healthy',\n",
    "                'Blueberry__healthy', 'Cherry__healthy', 'Cherry__Powdery_mildew', 'Corn__Cercospora_leaf_spot Grat_leaf_spot',\n",
    "                'Corn__Common_rust', 'Corn__healthy', 'Corn__Northern_Leaf_Blight', 'Grape__Black_rot', 'Grape__Esca_(Black_Measles)',\n",
    "                'Grape__healthy', 'Grape__Leaf_blight_(Isariopsis_Leaf_Spot)', 'Orange__Haunglongbing_(Citrus_greening)',\n",
    "                'Peach__Bacterial_spot', 'Peach__healthy', 'Pepper,_bell__Bacterial_spot', 'Pepper,_bell__healthy',\n",
    "                'Potato__Early_blight', 'Potato__healthy', 'Potato__Late_blight', 'Raspberry__healthy', 'Soybean__healthy',\n",
    "                'Squash__Powdery_mildew', 'Strawberry__healthy', 'Strawberry__Leaf_scorch', 'Tomato__Bacterial_spot',\n",
    "                'Tomato__Early_blight', 'Tomato__healthy', 'Tomato__Late_blight', 'Tomato__Leaf_Mold', 'Tomato__Septoria_leaf_spot',\n",
    "                'Tomato__Spider_mites Two-spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus',\n",
    "                'Tomato__Tomato_Yellow_Leaf_Curl_Virus']\n",
    "\n",
    "# 1. Data Preprocessing for Test Data\n",
    "def load_test_data(test_dir, img_size, batch_size):\n",
    "    \"\"\"Loads and preprocesses the test data.\"\"\"\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Only rescaling for test data\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False  # Ensure data order matches predictions\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "# 2. Load the Saved Model\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Loads the trained model.\"\"\"\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model\n",
    "\n",
    "# 3. Evaluate the Model\n",
    "def evaluate_model(model, test_generator):\n",
    "    \"\"\"Evaluates the model on test data and calculates metrics.\"\"\"\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class indices\n",
    "    y_true = test_generator.classes  # True labels\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(y_true, y_pred_classes, target_names=list(test_generator.class_indices.keys()), output_dict=True)\n",
    "\n",
    "    # PrettyTable for classification report\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "\n",
    "    for class_name, metrics in report.items():\n",
    "        if class_name not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:  # Skip aggregate metrics\n",
    "            table.add_row([\n",
    "                class_name,\n",
    "                f\"{metrics['precision']:.2f}\",\n",
    "                f\"{metrics['recall']:.2f}\",\n",
    "                f\"{metrics['f1-score']:.2f}\",\n",
    "                int(metrics['support'])\n",
    "            ])\n",
    "\n",
    "    # Add overall metrics\n",
    "    table.add_row([\"Overall (Accuracy)\", \"-\", \"-\", f\"{report['accuracy']:.2f}\", sum(y_true)])\n",
    "    table.add_row([\"Macro Avg\", f\"{report['macro avg']['precision']:.2f}\", f\"{report['macro avg']['recall']:.2f}\",\n",
    "                   f\"{report['macro avg']['f1-score']:.2f}\", \"-\"])\n",
    "    table.add_row([\"Weighted Avg\", f\"{report['weighted avg']['precision']:.2f}\", f\"{report['weighted avg']['recall']:.2f}\",\n",
    "                   f\"{report['weighted avg']['f1-score']:.2f}\", \"-\"])\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "    # Use LabelEncoder for numeric labels\n",
    "    encoder = LabelEncoder()\n",
    "    numeric_class_labels = encoder.fit_transform(class_labels)  # Numeric labels 0 to 37\n",
    "\n",
    "    # Update confusion matrix class names to numeric labels\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(12, 10))  # Adjust figure size\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=numeric_class_labels, yticklabels=numeric_class_labels,\n",
    "                annot_kws={\"size\": 8})  # Decrease font size of annotations\n",
    "    plt.xticks(ha='right')  # Rotate x-axis labels\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()  # Automatically adjust layout to avoid cutoff\n",
    "    plt.show()\n",
    "\n",
    "    # To map back numeric labels to class names if needed\n",
    "    print(\"Class mapping:\")\n",
    "    for numeric_label, class_label in zip(numeric_class_labels, class_labels):\n",
    "        print(f\"{numeric_label}: {class_label}\")\n",
    "\n",
    "\n",
    "# 4. Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load test data\n",
    "    test_generator = load_test_data(TEST_DIR, IMG_SIZE, BATCH_SIZE)\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_trained_model(MODEL_SAVE_PATH)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating model on test data...\")\n",
    "    evaluate_model(model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5anoA2tfg_He"
   },
   "source": [
    "5. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOrZ1Ivfg-5-"
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# --- Paths and Configuration ---\n",
    "MODEL_SAVE_PATH = \"saved_models/model_resnet50.h5\"\n",
    "IMG_SIZE = (224, 224)\n",
    "CLASS_LABELS = ['Apple__Apple_scab', 'Apple__Black_rot', 'Apple__Cedar_apple_rust', 'Apple__healthy',\n",
    "                'Blueberry__healthy', 'Cherry__healthy', 'Cherry__Powdery_mildew',\n",
    "                'Corn__Cercospora_leaf_spot Grat_leaf_spot', 'Corn__Common_rust', 'Corn__healthy',\n",
    "                'Corn__Northern_Leaf_Blight', 'Grape__Black_rot', 'Grape__Esca_(Black_Measles)',\n",
    "                'Grape__healthy', 'Grape__Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    "                'Orange__Haunglongbing_(Citrus_greening)', 'Peach__Bacterial_spot', 'Peach__healthy',\n",
    "                'Pepper,_bell__Bacterial_spot', 'Pepper,_bell__healthy', 'Potato__Early_blight',\n",
    "                'Potato__healthy', 'Potato__Late_blight', 'Raspberry__healthy', 'Soybean__healthy',\n",
    "                'Squash__Powdery_mildew', 'Strawberry__healthy', 'Strawberry__Leaf_scorch',\n",
    "                'Tomato__Bacterial_spot', 'Tomato__Early_blight', 'Tomato__healthy', 'Tomato__Late_blight',\n",
    "                'Tomato__Leaf_Mold', 'Tomato__Septoria_leaf_spot', 'Tomato__Spider_mites Two-spotted_spider_mite',\n",
    "                'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus', 'Tomato__Tomato_Yellow_Leaf_Curl_Virus']\n",
    "\n",
    "# --- Load Model ---\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Loads the trained model.\"\"\"\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model\n",
    "\n",
    "# --- Image Preprocessing ---\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocesses an image for prediction.\"\"\"\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)  # Load and resize image\n",
    "    img_array = img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# --- GUI Code ---\n",
    "def launch_gui(model):\n",
    "    \"\"\"Launches the GUI for the plant disease prediction.\"\"\"\n",
    "    def show_image(image_path):\n",
    "        \"\"\"Displays the image in the GUI.\"\"\"\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((250, 250))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        img_label.config(image=img)\n",
    "        img_label.image = img\n",
    "\n",
    "    def predict_image():\n",
    "        \"\"\"Handles image prediction when the user selects an image.\"\"\"\n",
    "        image_path = filedialog.askopenfilename(title=\"Select an Image\", filetypes=[(\"Image Files\", \"*.jpg *.png *.jpeg\")])\n",
    "        if image_path:\n",
    "            try:\n",
    "                # Preprocess the image\n",
    "                img_array = preprocess_image(image_path)\n",
    "                # Predict using the model\n",
    "                predictions = model.predict(img_array)\n",
    "                predicted_class_index = np.argmax(predictions)\n",
    "                confidence_score = predictions[0][predicted_class_index]\n",
    "                predicted_class_label = CLASS_LABELS[predicted_class_index]\n",
    "\n",
    "                # Split the label to extract plant species and disease\n",
    "                plant_species, disease = predicted_class_label.split(\"__\", 1)\n",
    "\n",
    "                # Display the results in the GUI\n",
    "                show_image(image_path)\n",
    "                species_label.config(text=f\"Plant Species: {plant_species}\")\n",
    "                result_label.config(text=f\"Leaf Disease: {disease}\")\n",
    "                confidence_label.config(text=f\"Confidence: {confidence_score:.4f}\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Failed to process image: {str(e)}\")\n",
    "\n",
    "    # GUI Window Setup\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Plant Disease Detection\")\n",
    "    window.geometry(\"600x600\")\n",
    "\n",
    "    # GUI Components\n",
    "    img_label = tk.Label(window)\n",
    "    img_label.pack(pady=10)\n",
    "\n",
    "    species_label = tk.Label(window, text=\"Plant Species: \", font=('Helvetica', 14, 'bold'), fg=\"green\")\n",
    "    species_label.pack(pady=10)\n",
    "\n",
    "    result_label = tk.Label(window, text=\"Leaf Disease: \", font=('Helvetica', 14, 'bold'), fg=\"red\")\n",
    "    result_label.pack(pady=10)\n",
    "\n",
    "    confidence_label = tk.Label(window, text=\"Confidence: \", font=('Helvetica', 12, 'italic'), fg=\"blue\")\n",
    "    confidence_label.pack(pady=10)\n",
    "\n",
    "    predict_button = tk.Button(window, text=\"Select Image to Predict\", command=predict_image, font=('Helvetica', 14))\n",
    "    predict_button.pack(pady=20)\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = load_trained_model(MODEL_SAVE_PATH)\n",
    "    # Launch the GUI\n",
    "    launch_gui(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
